{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae645ee1-8b9a-4d75-a4ff-919e4bf1c131",
   "metadata": {},
   "source": [
    "# Implementation of Reinforcement Learning algorithms for cliffwalking environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce52310-6b74-49ed-b607-330b66ef5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym.spaces\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "env = gym.make('CliffWalking-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c84e5a-6aab-497c-b07d-899a421598b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute():\n",
    "    print (\"Ausführungsphase\")\n",
    "    # Umgebung zurücksetzen\n",
    "    env.reset()\n",
    "    # Variablen initialisieren\n",
    "    done = False\n",
    "    steps = 0\n",
    "    score = 0\n",
    "    \n",
    "    while(done == False):\n",
    "        # Bewertung der Aktionen:\n",
    "        # -100 für Fallen (Cliff)\n",
    "        # -1 für alle anderen Aktionen\n",
    "        # next_state, reward, done, _ = env.step(action)\n",
    "        # 0 = Up, 1 = Right, 2 = Down, 3 = Left\n",
    "        \n",
    "        # Zählt die Schritte bis zum Spielende\n",
    "        steps += 1\n",
    "        # Wählt eine zufällige Aktion aus allen verfügbaren (dem action_space)\n",
    "        action = env.action_space.sample() \n",
    "              \n",
    "        # Führe die ausgewählte Aktion aus\n",
    "        _, reward, done,_ = env.step(action)\n",
    "        \n",
    "        score += reward\n",
    "        \n",
    "    print (f\"Schritte: {steps}, Ergebnis: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d14aa1f-9867-4c16-b7e4-e8d672b7b2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ausführungsphase\n",
      "Schritte: 233, Ergebnis: -1421\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae4908a-363c-46db-a771-9830240e4886",
   "metadata": {},
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd334f7e-95a0-4a10-8bd9-cb2bdf1fcb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(episodes):\n",
    "    print (\"Lernphase\")\n",
    "   \n",
    "    # Epsilon für Exploration\n",
    "    epsilon = 1\n",
    "    \n",
    "    # Lernparameter\n",
    "    alpha = 0.6\n",
    "    gamma = 1\n",
    "    scores = []\n",
    "    \n",
    "    # Lernen\n",
    "    for episode in range(episodes):\n",
    "        # Zurücksetzen der Umgebung vor jeder neuen Episode, Merken des Startzustandes\n",
    "        state = env.reset()\n",
    "        # Variablen initialisieren\n",
    "        score = 0\n",
    "        done = False\n",
    "        \n",
    "        # Gehe bis zum Spielende für jede Episode durch\n",
    "        while(done == False):\n",
    "            \n",
    "            # Wähle die am besten bewertete Aktion mit Wahrscheinlichkeit 1-epsilon\n",
    "            if random.uniform(0, 1) > epsilon:\n",
    "                action = np.argmax(Q1[state, :])\n",
    "            else:\n",
    "                # Sonst führe eine zufällige Aktion aus\n",
    "                action = env.action_space.sample()\n",
    "            \n",
    "            \n",
    "            # Führe die ausgewählte Aktion aus\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            \n",
    "            # Aktualisierung der Q Werte, Index ist aktueller Status und die ausgeführte Aktion\n",
    "            # Q-Learning Formel\n",
    "            Q1[state, action] = (1 - alpha) * Q1[state, action] + alpha * (reward + gamma * np.max(Q1[next_state, :]))\n",
    "            \n",
    "            # Neuen Zustand setzen\n",
    "            state = next_state\n",
    "            \n",
    "            \n",
    "        scores.append(score)\n",
    "        # Zeige die Bewertungen einer Episode graphisch über der Anzahl Episoden an\n",
    "        plot.plot(scores, \".\")\n",
    "        \n",
    "        # Ausgabe alle 1000 Episoden\n",
    "        if(episode % 10 == 0):\n",
    "            print (f\"Iteration: {episode}, Ergebnis: {score}\")\n",
    "                    \n",
    "        # Epsilon für jede Episode reduzieren falls es noch über einem Minimalwert liegt\n",
    "        if (epsilon > 0.01):\n",
    "            epsilon *= 0.98\n",
    "            \n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc49292-8a3c-4723-a469-e35f202bbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(cycles):\n",
    "    print (\"Ausführungsphase\")    \n",
    "    \n",
    "    all_steps = 0\n",
    "    scores = 0\n",
    "    \n",
    "    for cycle in range(cycles):\n",
    "        \n",
    "        # Zurücksetzen der Umgebung und Variablen initialisieren\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        steps = 0\n",
    "        \n",
    "        if (cycle == 99):\n",
    "            # Startzustand anzeigen (letzter Lauf)\n",
    "            env.render()\n",
    "    \n",
    "        while(done == False):\n",
    "            # Zähle Schritte bis zum Ziel hoch\n",
    "            steps += 1\n",
    "            # Wähle die am Besten bewertete Aktion aus\n",
    "            action = np.argmax(Q1[state, :])\n",
    "            # Führe die ausgewählte Aktion aus\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            # Weitergehen\n",
    "            state = next_state\n",
    "        \n",
    "            if (cycle == 99):\n",
    "                # Zeige den aktuellen Zustand für den letzten Lauf\n",
    "                env.render()\n",
    "                \n",
    "        all_steps += steps\n",
    "        scores += score\n",
    "                \n",
    "        if (cycle == 99):\n",
    "            print (f\"Schritte: {steps}, Ergebnis: {score}\")\n",
    "        \n",
    "    print ((f\"Für {cycles} Zyklen: durchschnittliche Schritte zum Ziel {all_steps/cycles}, durchschnittliches Ergebnis: {scores/cycles}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "044b64c5-e69e-46cf-b08c-6bc530eeecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lernphase\n",
      "Iteration: 0, Ergebnis: -130835\n",
      "Iteration: 10, Ergebnis: -832\n",
      "Iteration: 20, Ergebnis: -1027\n",
      "Iteration: 30, Ergebnis: -136\n",
      "Iteration: 40, Ergebnis: -131\n",
      "Iteration: 50, Ergebnis: -14\n",
      "Iteration: 60, Ergebnis: -232\n",
      "Iteration: 70, Ergebnis: -20\n",
      "Iteration: 80, Ergebnis: -13\n",
      "Iteration: 90, Ergebnis: -224\n",
      "Ausführungsphase\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  x  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  x  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  x  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  x  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  x  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  x  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  x  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  x  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  x  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  x  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  x\n",
      "\n",
      "Schritte: 13, Ergebnis: -13\n",
      "Für 100 Zyklen: durchschnittliche Schritte zum Ziel 13.0, durchschnittliches Ergebnis: -13.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD4CAYAAADGmmByAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAadElEQVR4nO3df5TV9X3n8edrZgTxJ+BQEGYIeMT0YLL+yK2SbNNYNYppLCY11uxuZbNUThLdJpzuJhhNWCPdjd2cxdoae6iwwZyeoiWJ0tWsi8Yk2+7BOMRERWOd6irDDwVBdKtiBt77x/0Mfhnunbkzn7n3yszrcc49fr/v7+f7uZ/vfIfv635/3FERgZmZ2XC1NHsAZmZ2ZHOQmJlZFgeJmZllcZCYmVkWB4mZmWVpa/YAGq29vT1mzZrV7GGYmR1RNm3atCsiplRaNuaCZNasWXR1dTV7GGZmRxRJL1Rb5ktbZmaWxUFiZmZZHCRmZpbFQWJmZlkcJGZmlmVUBImk+ZKekdQtaWmzx2NmNpYc8Y//SmoFbgM+CvQAj0paHxFPNXdkY9ONK26gZ3o7Hdt2sWzJ8rr3lfN+xXWBQ/qp1m+1dfqvP9j4aumnlv6H01ctP6ecPvtvcz1+BtWnRc/0k+jY9kqqHz69bMlNB8fw9RVfZcv0k+jc9gpfW3ITX7/lq2w5+SQ6t78CamHLtEl07tiDgBenTWLmjj2AeHHaRGbueBUEL06dyMyXXkUt4oUpJ/KenXtB4oX2E3jPrtdoQTzffjyzd72OWlp5bvIxnLL7Da773FcOjuOWO27mqePHM/f1fdA6nqeOFXP/OTi67WgeG/82Z+0bx2f/4LOs/O6d/IzXOZvjOfrYo9j45h7mTZjE0cefyN/v3cZvnjidthPG85NdPfxWeweTJ0/ixzu38JEpnRx33Hv5P6/+Pz408ThKJx476O/AUOhI/zPykj4I/KeIuDjNXwcQEf+lUvtSqRTv1u+R1PIPbqCDwEgdxIf6D7+vzY0rbmDVGZfSSxtt9HLZlh/x5tHjBz1Q19LXol/83SHLeqa3M+GtfdzTeV5N79d/G4rrtrAfgAO0HuynUr/V1qm0fv/2Q+2nlv77trPv5zTc9fvvh6GOb7BtHumfQc50rWNtzDh+zJtHj+OYfW/z/Y6PDPp79akdG/nbafOGNj7BgWilRftp0VHsD3FUi1h35qlDDhNJmyKiVHHZKAiSy4H5EfGHaf4PgHMj4tpCm8XAYoCZM2d+4IUXqn6vpmmqHTgHOqDWsn7fslo/2Q/14Fd8r6vvuoX7pnyYA2pF0UsLEGjAA3W1f+SvHj2Bfzi+xAG10hK9fOj1TUx6681DxiGCA4io4f36b8Oh6+4nEKiFlujl13/1LL886rTDtqPaOodOV2s/1H4G77+NXs59/ecHf05DXb/aAWjo46u8bfk/y3pM1zrW5oyjWvv88R0AiUC0Al8+5WT+6D1Th3SMGihIjvhLW7WIiJXASiifkTR5OBUP7D3T2+mljQNqpTeCnuntA9b7q9bukICZ0ssra24+7NPohLf2cU9qU/yl/lUE3+284LBf9ggO/oL2RvDEKZ1cfdctTHhrH2300huBoGr7J6fNPDjW4rLi+7Wwv3xwi6CFA2w8/iwOHN//INdLC0FEb9X3q7YNxXVbOADAgWihjf28b8eLdHeecth2VFunOF2t/VD7qaX/3ggCDv7Mh7p+8edUnB7q+KptW+7Psh7TtY61WeOo1r6N/Zz1yst0Txvi+A47I4GjWsSHJh7HSBoNQbIV6CzMd6Tau1L/AzsrbmDZkuV0bNtF25TyAaGN/Ux4a99hB+c29h8MgL6++gKpAw5ZvxgUfQftQw7UU6p9Ah36wa/vIF/x03+/X/qB/sEW34+Ig2chxbOT/v/4B3u/gQ4cA10KO6n/GVr6udZ8Wahf+6H2U2v/739uC+9ny7DWH+igNZTxDbRtOT/LetwjqTaGvnsk7Q26RzLhrbe5p/MjB8fxiZ4f8+b4cYPcI/kC7826R3Ja3e6RjIYgeRSYI2k25QC5EvhXzR1SddXOHJYtWQ41XPuveA9hSvny0qJf/N1hZzrFgKr2abSWg3O1f/jFg3xvBG8ePZ6/+v0vAhw8gAx0oB7sINl3ee+RM86seqDqU0uf1dbtr1q/tdx7qtZ+qP0Mtf/hrA/DvyFf65jq8TPIcdKKr1a88Q7wtS/eVGWtkdf5l/+Zf5x0DKfteYP/+NmvDL4CsPj3rjpkvjh3RWH6k4Xp82acfXB6pAOkzxF/jwRA0seAW4BWYHVE/Em1ts2+2f5OALTSxv6K9zyK9xpaopff2fn3Bw/OtbapdDP7nYBqfecTKId/Ah3Kjf5atmeoP5+cBw6G0qeZ1W7U3yOJiPuB+5s9jloUzzyqHdj6X+YqXs6qpU2ls5VazhKqjjdze4ZiuOMYTp9mNjJGxRnJUNTjjKQen3hzvkNRyxmNmdlQjPozkmaqdvM8V84X8Go5ozEzGykOkky1Pp47EmoNrZG+3GRmNhAHSabB7lWM5MF8KKHl8DCzRnGQZKr26b8el7x8ycrM3o0cJMM02NlGPS55+ZKVmb0bOUiGoZazjXqdPTg8zOzdxkEyDLWcbfjswczGCgfJMNR6tuHwMLOxwEEyDCN5tuE/32FmRzoHyTCNxEG/Xl9mNDNrJAdJEzXyy4xmZvXS0uwBjGUd23bRRi8t6c+3+3shZnYk8hlJE/nJLjMbDRwkI2yoN88dHmZ2pHOQjCDfPDezschBMoJ889zMxiLfbB9BvnluZmORz0hGkG+em9lY5CAZYQ4PMxtrfGnLzMyy1C1IJP1XSb+U9Lik70uaWFh2naRuSc9IurhQn59q3ZKWFuqzJT2S6ndJGpfq49N8d1o+q17bY2ZmldXzjGQD8L6I+BfAPwLXAUiaC1wJnA7MB74lqVVSK3AbcAkwF/h0agtwM7AiIk4F9gCLUn0RsCfVV6R2ZmbWQHULkoj4XxHRm2Y3Ah1pegGwNiL2RcTzQDdwTnp1R8RzEfE2sBZYIEnA+cC6tP4a4LJCX2vS9DrggtTezMwapFH3SP4d8IM0PQPYUljWk2rV6icBrxZCqa9+SF9p+d7U/hCSFkvqktS1c+fOEdkgMzMry3pqS9KDwLQKi66PiHtTm+uBXuCvc94rR0SsBFYClEqlaNY4zMxGo6wgiYgLB1ou6d8CHwcuiIi+A/hWoLPQrCPVqFJ/BZgoqS2ddRTb9/XVI6kNODG1NzOzBqnnU1vzgS8BvxsRbxQWrQeuTE9czQbmAD8FHgXmpCe0xlG+Ib8+BdDDwOVp/YXAvYW+Fqbpy4EfFgLLzMwaoJ5fSPwLYDywId3/3hgRn42IzZLuBp6ifMnrmojYDyDpWuABoBVYHRGbU19fBtZKWg48BqxK9VXAdyR1A7sph4+ZmTWQxtoH+FKpFF1dXc0ehpnZEUXSpogoVVrmb7abmVkWB4mZmWVxkJiZWRYHiZmZZXGQmJlZFgeJmZllcZCYmVkWB4mZmWVxkJiZWRYHiZmZZXGQmJlZFgeJmZllcZCYmVkWB4mZmWVxkJiZWRYHiZmZZXGQmJlZFgeJmZllcZCYmVkWB4mZmWVxkJiZWRYHiZmZZal7kEj6Y0khqT3NS9KtkrolPS7p7ELbhZKeTa+FhfoHJD2R1rlVklJ9sqQNqf0GSZPqvT1mZnaougaJpE7gIuDFQvkSYE56LQZuT20nA8uAc4FzgGWFYLgduLqw3vxUXwo8FBFzgIfSvJmZNVC9z0hWAF8ColBbANwZZRuBiZJOBi4GNkTE7ojYA2wA5qdlJ0TExogI4E7gskJfa9L0mkLdzMwapG5BImkBsDUiftFv0QxgS2G+J9UGqvdUqANMjYjtaXoHMLXKWBZL6pLUtXPnzuFsjpmZVdGWs7KkB4FpFRZdD3yF8mWthoiIkBRVlq0EVgKUSqWKbczMbHiygiQiLqxUl/R+YDbwi3RfvAP4maRzgK1AZ6F5R6ptBc7rV/9RqndUaA/wkqSTI2J7ugT2cs721NONK26gZ3o7Hdt2sWzJ8mYPx8xsxNTl0lZEPBERvxYRsyJiFuXLUWdHxA5gPXBVenprHrA3XZ56ALhI0qR0k/0i4IG07DVJ89LTWlcB96a3Wg/0Pd21sFB/V7lxxQ2sOuNS7pvyYVadcSk3rrih2UMyMxsxWWckw3Q/8DGgG3gD+AxAROyWdBPwaGr39YjYnaY/D3wbmAD8IL0AvgHcLWkR8AJwRSM2YKh6prfTSxsH1EpvBD3T25s9JDOzEdOQIElnJX3TAVxTpd1qYHWFehfwvgr1V4ALRmygddKxbRdtU3rpjaCN/XRs29XsIZmZjZhmnJGMOcuWLAffIzGzUcpB0iAODzMbrfy3tszMLIuDxMzMsjhIzMwsi4PEzMyyOEjMzCyLg8TMzLI4SMzMLIuDxMzMsjhIzMwsi4PEzMyyOEjMzCyLg8TMzLI4SMzMLIuDxMzMsjhIzMwsi4PEzMyyOEjMzCyLg8TMzLI4SMzMLEtdg0TSv5f0S0mbJf1poX6dpG5Jz0i6uFCfn2rdkpYW6rMlPZLqd0kal+rj03x3Wj6rnttjZmaHq1uQSPptYAFwRkScDnwz1ecCVwKnA/OBb0lqldQK3AZcAswFPp3aAtwMrIiIU4E9wKJUXwTsSfUVqZ2ZmTVQPc9IPgd8IyL2AUTEy6m+AFgbEfsi4nmgGzgnvboj4rmIeBtYCyyQJOB8YF1afw1wWaGvNWl6HXBBam9mZg1SzyA5DfhwuuT0Y0m/keozgC2Fdj2pVq1+EvBqRPT2qx/SV1q+N7U/hKTFkrokde3cuXNENs7MzMraclaW9CAwrcKi61Pfk4F5wG8Ad0s6Jef9hisiVgIrAUqlUjRjDGZmo1VWkETEhdWWSfoc8L2ICOCnkg4A7cBWoLPQtCPVqFJ/BZgoqS2ddRTb9/XVI6kNODG1NzOzBqnnpa17gN8GkHQaMA7YBawHrkxPXM0G5gA/BR4F5qQntMZRviG/PgXRw8Dlqd+FwL1pen2aJy3/YWpvZmYNknVGMojVwGpJTwJvAwvTQX6zpLuBp4Be4JqI2A8g6VrgAaAVWB0Rm1NfXwbWSloOPAasSvVVwHckdQO7KYePmZk1kMbaB/hSqRRdXV3NHoaZ2RFF0qaIKFVa5m+2m5lZFgeJmZllcZCYmVkWB4mZmWVxkJiZWRYHiZmZZXGQmJlZFgeJmZllcZCYmVkWB4mZmWVxkJiZWRYHiZmZZXGQmJlZFgeJmZllcZCYmVkWB4mZmWVxkJiZWRYHiZmZZXGQmJlZFgeJmZllcZCYmVmWugWJpDMlbZT0c0ldks5JdUm6VVK3pMclnV1YZ6GkZ9NrYaH+AUlPpHVulaRUnyxpQ2q/QdKkem2PmZlVVs8zkj8FboyIM4GvpXmAS4A56bUYuB3KoQAsA84FzgGWFYLhduDqwnrzU30p8FBEzAEeSvNmZtZA9QySAE5I0ycC29L0AuDOKNsITJR0MnAxsCEidkfEHmADMD8tOyEiNkZEAHcClxX6WpOm1xTqZmbWIG117PuLwAOSvkk5sD6U6jOALYV2Pak2UL2nQh1gakRsT9M7gKmVBiJpMeWzH2bOnDm8rTEzs4qygkTSg8C0CouuBy4AlkTEdyVdAawCLsx5v4FEREiKKstWAisBSqVSxTZmZjY8WUESEVWDQdKdwBfS7N8Cd6TprUBnoWlHqm0FzutX/1Gqd1RoD/CSpJMjYnu6BPbysDbEzMyGrZ73SLYBH0nT5wPPpun1wFXp6a15wN50eeoB4CJJk9JN9ouAB9Ky1yTNS09rXQXcW+ir7+muhYW6mZk1SD3vkVwN/JmkNuAt0j0K4H7gY0A38AbwGYCI2C3pJuDR1O7rEbE7TX8e+DYwAfhBegF8A7hb0iLgBeCKOm6PmZlVoPKDUGNHqVSKrq6uZg/DzOyIImlTRJQqLfM3283MLIuDxMzMsjhIzMwsi4PEzMyyOEjMzCyLg8TMzLI4SMzMLIuDxMzMsjhIzMwsi4PEzMyyOEjMzCyLg8TMzLI4SMzMLIuDxMzMsjhIzMwsi4PEzMyyOEjMzCyLg8TMzLI4SMzMLIuDxMzMsjhIzMwsS1aQSPqUpM2SDkgq9Vt2naRuSc9IurhQn59q3ZKWFuqzJT2S6ndJGpfq49N8d1o+a7D3MDOzxsk9I3kS+CTwk2JR0lzgSuB0YD7wLUmtklqB24BLgLnAp1NbgJuBFRFxKrAHWJTqi4A9qb4itav6HpnbY2ZmQ5QVJBHxdEQ8U2HRAmBtROyLiOeBbuCc9OqOiOci4m1gLbBAkoDzgXVp/TXAZYW+1qTpdcAFqX219zAzswaq1z2SGcCWwnxPqlWrnwS8GhG9/eqH9JWW703tq/V1GEmLJXVJ6tq5c2fGZpmZWX9tgzWQ9CAwrcKi6yPi3pEf0siLiJXASoBSqRRNHo6Z2agyaJBExIXD6Hcr0FmY70g1qtRfASZKaktnHcX2fX31SGoDTkztB3oPMzNrkHpd2loPXJmeuJoNzAF+CjwKzElPaI2jfLN8fUQE8DBweVp/IXBvoa+Fafpy4IepfbX3MDOzBhr0jGQgkj4B/DkwBbhP0s8j4uKI2CzpbuApoBe4JiL2p3WuBR4AWoHVEbE5dfdlYK2k5cBjwKpUXwV8R1I3sJty+DDQe5iZWeOo/OF+7CiVStHV1dXsYZiZHVEkbYqIUqVl/ma7mZllcZCYmVkWB4mZmWVxkJiZWRYHiZmZZXGQmJlZFgeJmZllcZCYmVkWB4mZmWVxkJiZWRYHiZmZZXGQmJlZFgeJmZllcZCYmVkWB4mZmWVxkJiZWRYHiZmZZXGQmJlZFgeJmZllcZCYmVkWB4mZmWXJChJJn5K0WdIBSaVC/aOSNkl6Iv33/MKyD6R6t6RbJSnVJ0vaIOnZ9N9Jqa7UrlvS45LOLvS1MLV/VtLCnG0xM7PhyT0jeRL4JPCTfvVdwKUR8X5gIfCdwrLbgauBOek1P9WXAg9FxBzgoTQPcEmh7eK0PpImA8uAc4FzgGV94WNmZo2TFSQR8XREPFOh/lhEbEuzm4EJksZLOhk4ISI2RkQAdwKXpXYLgDVpek2/+p1RthGYmPq5GNgQEbsjYg+wgXdCyczMGqQR90h+D/hZROwDZgA9hWU9qQYwNSK2p+kdwNQ0PQPYUmGdanUzM2ugtsEaSHoQmFZh0fURce8g654O3AxcNJRBRURIiqGsM8g4FlO+LMbMmTNHqlszM6OGIImIC4fTsaQO4PvAVRHxT6m8FegoNOtINYCXJJ0cEdvTpauXC+t0VlhnK3Bev/qPqmzDSmAlQKlUGrGAMjOzOl3akjQRuA9YGhH/0FdPl65ekzQvPa11FdB3VrOe8o150n+L9avS01vzgL2pnweAiyRNSjfZL0o1MzNroNzHfz8hqQf4IHCfpL4D+bXAqcDXJP08vX4tLfs8cAfQDfwT8INU/wbwUUnPAhemeYD7gedS+79K6xMRu4GbgEfT6+upZmZmDaTyw1NjR6lUiq6urmYPw8zsiCJpU0SUKi3zN9vNzCyLg8TMzLI4SMzMLIuDxMzMsjhIzMwsi4PEzMyyOEjMzCyLg8TMzLI4SMzMLMugf7TR3nHjihvomd5Ox7ZdLFuyvNnDMTN7V3CQ1OjGFTew6oxL6aWNtim9sOIGh4mZGQ6SmvVMb6eXNg6old4Ieqa3N3tIZmbvCr5HUqOObbtoo5eW6KWN/XRs29XsIZmZvSv4jKRGy5YsB98jMTM7jINkCBweZmaH86UtMzPL4iAxM7MsDhIzM8viIDEzsywOEjMzy+IgMTOzLIqIZo+hoSTtBF7I6KIdGGvfRhyL2wxjc7u9zWPHULf7PRExpdKCMRckuSR1RUSp2eNopLG4zTA2t9vbPHaM5Hb70paZmWVxkJiZWRYHydCtbPYAmmAsbjOMze32No8dI7bdvkdiZmZZfEZiZmZZHCRmZpbFQVIjSfMlPSOpW9LSZo+nHiR1SnpY0lOSNkv6QqpPlrRB0rPpv5OaPdZ6kNQq6TFJ/yPNz5b0SNrnd0ka1+wxjiRJEyWtk/RLSU9L+uBY2NeSlqTf7ycl/Y2ko0fjvpa0WtLLkp4s1CruX5Xdmrb/cUlnD+W9HCQ1kNQK3AZcAswFPi1pbnNHVRe9wB9HxFxgHnBN2s6lwEMRMQd4KM2PRl8Ani7M3wysiIhTgT3AoqaMqn7+DPifEfHrwBmUt31U72tJM4A/AkoR8T6gFbiS0bmvvw3M71ertn8vAeak12Lg9qG8kYOkNucA3RHxXES8DawFFjR5TCMuIrZHxM/S9OuUDywzKG/rmtRsDXBZUwZYR5I6gN8B7kjzAs4H1qUmo2q7JZ0I/BawCiAi3o6IVxkD+5ry/9BvgqQ24BhgO6NwX0fET4Dd/crV9u8C4M4o2whMlHRyre/lIKnNDGBLYb4n1UYtSbOAs4BHgKkRsT0t2gFMbda46ugW4EvAgTR/EvBqRPSm+dG2z2cDO4H/ni7n3SHpWEb5vo6IrcA3gRcpB8heYBOje18XVdu/Wcc4B4kdRtJxwHeBL0bEa8VlUX5efFQ9My7p48DLEbGp2WNpoDbgbOD2iDgL+Gf6XcYapft6EuVP37OB6cCxHH75Z0wYyf3rIKnNVqCzMN+RaqOOpKMoh8hfR8T3UvmlvtPc9N+XmzW+OvmXwO9K+r+UL1ueT/n+wcR0+QNG3z7vAXoi4pE0v45ysIz2fX0h8HxE7IyIXwHfo7z/R/O+Lqq2f7OOcQ6S2jwKzElPdoyjfHNufZPHNOLSfYFVwNMR8d8Ki9YDC9P0QuDeRo+tniLiuojoiIhZlPftDyPiXwMPA5enZqNquyNiB7BF0ntT6QLgKUb5vqZ8SWuepGPS73vfdo/afd1Ptf27HrgqPb01D9hbuAQ2KH+zvUaSPkb5OnorsDoi/qS5Ixp5kn4T+N/AE7xzr+ArlO+T3A3MpPwn+K+IiP438UYFSecB/yEiPi7pFMpnKJOBx4B/ExH7mji8ESXpTMoPF4wDngM+Q/nD5aje15JuBH6f8lOKjwF/SPl+wKja15L+BjiP8p+LfwlYBtxDhf2bQvUvKF/mewP4TER01fxeDhIzM8vhS1tmZpbFQWJmZlkcJGZmlsVBYmZmWRwkZmaWxUFiZmZZHCRmZpbl/wOns5hbNaUKwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrix für Q-Werte, initial auf 0\n",
    "Q1 = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "\n",
    "learn(100)\n",
    "execute(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f5d7163-bbca-4525-bffd-56135699caa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated Optimal Policy (UP = 0, RIGHT = 1, DOWN = 2, LEFT = 3, N/A = -1):\n",
      "[[2 2 1 1 1 1 1 2 2 2 2 2]\n",
      " [2 1 2 1 1 2 1 2 1 1 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# print the estimated optimal policy\n",
    "policy_q = np.array([np.argmax(Q1[key])for key in np.arange(48)]).reshape((4,12))\n",
    "\n",
    "print(\"\\nEstimated Optimal Policy (UP = 0, RIGHT = 1, DOWN = 2, LEFT = 3, N/A = -1):\")\n",
    "print(policy_q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b432e3e-4c70-4804-bb57-6c72b199c8ce",
   "metadata": {},
   "source": [
    "# SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79c85c5c-f7a0-4c91-8a1b-963446a89c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, epsilon):\n",
    "    # Wähle die am besten bewertete Aktion mit Wahrscheinlichkeit 1-epsilon\n",
    "    if random.uniform(0, 1) > epsilon:\n",
    "        action = np.argmax(Q2[state, :])\n",
    "    else:\n",
    "        # Sonst führe eine zufällige Aktion aus\n",
    "        action = env.action_space.sample()\n",
    "    return action        \n",
    "            \n",
    "    \n",
    "def learn(episodes):\n",
    "    print (\"Lernphase\")\n",
    "    \n",
    "    # Epsilon für Exploration\n",
    "    epsilon = 1\n",
    "    \n",
    "    # Lernparameter\n",
    "    alpha = 0.2\n",
    "    gamma = 1\n",
    "    scores = [];\n",
    "    \n",
    "    \n",
    "    # Lernen\n",
    "    for episode in range(episodes):\n",
    "        # Zurücksetzen der Umgebung vor jeder neuen Episode, Merken des Startzustandes\n",
    "        state = env.reset()\n",
    "        # Variablen initialisieren\n",
    "        score = 0\n",
    "        done = False\n",
    "        action = get_action(state, epsilon)\n",
    "        \n",
    "        while(done == False):\n",
    "                        \n",
    "            # Führe die ausgewählte Aktion aus\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            \n",
    "            # Nächste Aktion aus dem nächsten Zustand errechnen, diese kann auch zufällig sein\n",
    "            next_action = get_action(next_state, epsilon)\n",
    "            \n",
    "            # Aktualisierung der Q Werte, Index ist aktueller Status und die ausgeführte Aktion\n",
    "            # SARSA Formel\n",
    "            Q2[state, action] = (1 - alpha) * Q2[state, action] + alpha * (reward + gamma * Q2[next_state, next_action])\n",
    "            \n",
    "            # Neuen Zustand und nächste Aktion setzen\n",
    "            state = next_state\n",
    "            action = next_action\n",
    "            \n",
    "        scores.append(score)\n",
    "        # Zeige die Bewertungen einer Episode graphisch über der Anzahl Episoden an\n",
    "        plot.plot(scores, \".\")\n",
    "            \n",
    "        # Ausgabe alle 1000 Episoden\n",
    "        if(episode % 10 == 0):\n",
    "            print (f\"Iteration: {episode}, Ergebnis: {score}\")\n",
    "            \n",
    "        # Epsilon reduzieren falls es noch über einem Minimalwert liegt\n",
    "        if (epsilon > 0.01):\n",
    "            epsilon *= 0.98\n",
    "            \n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e21d3cf0-467c-4f53-b62e-20548d3de3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(cycles):\n",
    "    print (\"Ausführungsphase\")    \n",
    "    \n",
    "    all_steps = 0\n",
    "    scores = 0\n",
    "    \n",
    "    for cycle in range(cycles):\n",
    "        \n",
    "        # Zurücksetzen der Umgebung und Variablen initialisieren\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        steps = 0\n",
    "        \n",
    "        if (cycle == 99):\n",
    "            # Startzustand anzeigen (letzter Lauf)\n",
    "            env.render()\n",
    "    \n",
    "        while(done == False):\n",
    "            # Zähle Schritte bis zum Ziel hoch\n",
    "            steps += 1\n",
    "            # Wähle die am Besten bewertete Aktion aus\n",
    "            action = np.argmax(Q2[state, :])\n",
    "            # Führe die ausgewählte Aktion aus\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            # Weitergehen\n",
    "            state = next_state\n",
    "        \n",
    "            if (cycle == 99):\n",
    "                # Zeige den aktuellen Zustand für den letzten Lauf\n",
    "                env.render()\n",
    "                \n",
    "        all_steps += steps\n",
    "        scores += score\n",
    "                \n",
    "        if (cycle == 99):\n",
    "            print (f\"Schritte: {steps}, Ergebnis: {score}\")\n",
    "        \n",
    "    print ((f\"Für {cycles} Zyklen: durchschnittliche Schritte zum Ziel {all_steps/cycles}, durchschnittliches Ergebnis: {scores/cycles}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "634b627d-0c26-4da4-9f83-b76523ad32a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lernphase\n",
      "Iteration: 0, Ergebnis: -87250\n",
      "Iteration: 10, Ergebnis: -2589\n",
      "Iteration: 20, Ergebnis: -43\n",
      "Iteration: 30, Ergebnis: -43\n",
      "Iteration: 40, Ergebnis: -39\n",
      "Iteration: 50, Ergebnis: -22\n",
      "Iteration: 60, Ergebnis: -119\n",
      "Iteration: 70, Ergebnis: -25\n",
      "Iteration: 80, Ergebnis: -26\n",
      "Iteration: 90, Ergebnis: -18\n",
      "Ausführungsphase\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  x  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  x  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  x  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  x  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  x  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  x  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  x  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  x  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  x  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  x  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  x\n",
      "\n",
      "Schritte: 17, Ergebnis: -17\n",
      "Für 100 Zyklen: durchschnittliche Schritte zum Ziel 17.0, durchschnittliches Ergebnis: -17.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrix für Q-Werte, initial auf 0\n",
    "Q2 = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "\n",
    "learn(100)\n",
    "execute(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "533bf448-efff-4ee3-8dbc-555671d63549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated Optimal Policy (UP = 0, RIGHT = 1, DOWN = 2, LEFT = 3, N/A = -1):\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 2]\n",
      " [0 0 0 1 1 0 0 0 0 0 1 2]\n",
      " [0 0 0 0 0 1 1 0 0 0 1 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# print the estimated optimal policy\n",
    "policy_sarsa = np.array([np.argmax(Q2[key])for key in np.arange(48)]).reshape((4,12))\n",
    "\n",
    "print(\"\\nEstimated Optimal Policy (UP = 0, RIGHT = 1, DOWN = 2, LEFT = 3, N/A = -1):\")\n",
    "print(policy_sarsa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b5290-7552-47d8-bacc-36d82061e8c1",
   "metadata": {},
   "source": [
    "## Sarsa $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad2af538-b060-448b-bed1-6870f77295bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, epsilon):\n",
    "    # Wähle die am besten bewertete Aktion mit Wahrscheinlichkeit 1-epsilon\n",
    "    if random.uniform(0, 1) > epsilon:\n",
    "        action = np.argmax(Q3[state, :])\n",
    "    else:\n",
    "        # Sonst führe eine zufällige Aktion aus\n",
    "        action = env.action_space.sample()\n",
    "    return action        \n",
    "            \n",
    "    \n",
    "def learn(episodes):\n",
    "    print (\"Lernphase\")\n",
    "    \n",
    "    # Epsilon für Exploration\n",
    "    epsilon = 1\n",
    "    \n",
    "    # Lernparameter\n",
    "    alpha = 0.2\n",
    "    gamma = 1\n",
    "    scores = [];\n",
    "    \n",
    "    \n",
    "    # Lernen\n",
    "    for episode in range(episodes):\n",
    "        # Zurücksetzen der Umgebung vor jeder neuen Episode, Merken des Startzustandes\n",
    "        state = env.reset()\n",
    "        # Variablen initialisieren\n",
    "        score = 0\n",
    "        done = False\n",
    "        action = get_action(state, epsilon)\n",
    "        \n",
    "        while(done == False):\n",
    "                        \n",
    "            # Führe die ausgewählte Aktion aus\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            \n",
    "            # Nächste Aktion aus dem nächsten Zustand errechnen, diese kann auch zufällig sein\n",
    "            next_action = get_action(next_state, epsilon)\n",
    "            \n",
    "            # Aktualisierung der Q Werte, Index ist aktueller Status und die ausgeführte Aktion\n",
    "            # Sarsamax Formel\n",
    "            Qsa_next = np.max(Q3[next_state]) if next_state is not None else 0  # value of next state \n",
    "            Q3[state, action] = (1 - alpha) * Q3[state, action] + alpha * (reward + gamma * Qsa_next)\n",
    "            \n",
    "            # Neuen Zustand und nächste Aktion setzen\n",
    "            state = next_state\n",
    "            action = next_action\n",
    "            \n",
    "        scores.append(score)\n",
    "        # Zeige die Bewertungen einer Episode graphisch über der Anzahl Episoden an\n",
    "        plot.plot(scores, \".\")\n",
    "            \n",
    "        # Ausgabe alle 1000 Episoden\n",
    "        if(episode % 10 == 0):\n",
    "            print (f\"Iteration: {episode}, Ergebnis: {score}\")\n",
    "            \n",
    "        # Epsilon reduzieren falls es noch über einem Minimalwert liegt\n",
    "        if (epsilon > 0.01):\n",
    "            epsilon *= 0.98\n",
    "            \n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada5e1c2-6671-4267-854d-16c8f925ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(cycles):\n",
    "    print (\"Ausführungsphase\")    \n",
    "    \n",
    "    all_steps = 0\n",
    "    scores = 0\n",
    "    \n",
    "    for cycle in range(cycles):\n",
    "        \n",
    "        # Zurücksetzen der Umgebung und Variablen initialisieren\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        steps = 0\n",
    "        \n",
    "        \n",
    "        if (cycle == 99):\n",
    "            # Startzustand anzeigen (letzter Lauf)\n",
    "            env.render()\n",
    "    \n",
    "        while(done == False):\n",
    "            # Zähle Schritte bis zum Ziel hoch\n",
    "            steps += 1\n",
    "            # Wähle die am Besten bewertete Aktion aus\n",
    "            action = np.argmax(Q3[state, :])\n",
    "            # Führe die ausgewählte Aktion aus\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            # Weitergehen\n",
    "            state = next_state\n",
    "        \n",
    "            if (cycle == 99):\n",
    "                # Zeige den aktuellen Zustand für den letzten Lauf\n",
    "                env.render()\n",
    "                \n",
    "        all_steps += steps\n",
    "        scores += score\n",
    "                \n",
    "        if (cycle == 99):\n",
    "            print (f\"Schritte: {steps}, Ergebnis: {score}\")\n",
    "        \n",
    "    print ((f\"Für {cycles} Zyklen: durchschnittliche Schritte zum Ziel {all_steps/cycles}, durchschnittliches Ergebnis: {scores/cycles}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "363311d8-48b0-4500-96aa-5e2c262365cd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lernphase\n",
      "Iteration: 0, Ergebnis: -89222\n",
      "Iteration: 10, Ergebnis: -2476\n",
      "Iteration: 20, Ergebnis: -4005\n",
      "Iteration: 30, Ergebnis: -366\n",
      "Iteration: 40, Ergebnis: -28\n",
      "Iteration: 50, Ergebnis: -136\n",
      "Iteration: 60, Ergebnis: -26\n",
      "Iteration: 70, Ergebnis: -15\n",
      "Iteration: 80, Ergebnis: -21\n",
      "Iteration: 90, Ergebnis: -15\n",
      "Ausführungsphase\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  x  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  x  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  x  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  x  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  x  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  x  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  x  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  x  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  x  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  x  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  x\n",
      "\n",
      "Schritte: 13, Ergebnis: -13\n",
      "Für 100 Zyklen: durchschnittliche Schritte zum Ziel 13.0, durchschnittliches Ergebnis: -13.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrix für Q-Werte, initial auf 0\n",
    "Q3 = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "\n",
    "learn(100)\n",
    "execute(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d8d3c6a-9573-4eeb-ac28-317043220e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated Optimal Policy (UP = 0, RIGHT = 1, DOWN = 2, LEFT = 3, N/A = -1):\n",
      "[[1 2 2 1 1 2 1 2 1 2 2 2]\n",
      " [1 1 1 1 2 1 2 2 1 1 2 2]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# print the estimated optimal policy\n",
    "policy_sarsamax = np.array([np.argmax(Q3[key]) for key in np.arange(48)]).reshape((4,12))\n",
    "\n",
    "print(\"\\nEstimated Optimal Policy (UP = 0, RIGHT = 1, DOWN = 2, LEFT = 3, N/A = -1):\")\n",
    "print(policy_sarsamax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
