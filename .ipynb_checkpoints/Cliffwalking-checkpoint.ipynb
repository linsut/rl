{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae645ee1-8b9a-4d75-a4ff-919e4bf1c131",
   "metadata": {},
   "source": [
    "# Implementation of Reinforcement Learning algorithms for cliffwalking environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce52310-6b74-49ed-b607-330b66ef5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym.spaces\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "env = gym.make('CliffWalking-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c84e5a-6aab-497c-b07d-899a421598b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute():\n",
    "    print (\"Ausführungsphase\")\n",
    "    # Umgebung zurücksetzen\n",
    "    env.reset()\n",
    "    # Variablen initialisieren\n",
    "    done = False\n",
    "    steps = 0\n",
    "    score = 0\n",
    "    \n",
    "    while(done == False):\n",
    "        # Bewertung der Aktionen:\n",
    "        # -100 für Fallen (Cliff)\n",
    "        # -1 für alle anderen Aktionen\n",
    "        # next_state, reward, done, _ = env.step(action)\n",
    "        # 0 = Up, 1 = Right, 2 = Down, 3 = Left\n",
    "        \n",
    "        # Zählt die Schritte bis zum Spielende\n",
    "        steps += 1\n",
    "        # Wählt eine zufällige Aktion aus allen verfügbaren (dem action_space)\n",
    "        action = env.action_space.sample() \n",
    "              \n",
    "        # Führe die ausgewählte Aktion aus\n",
    "        _, reward, done,_ = env.step(action)\n",
    "        \n",
    "        score += reward\n",
    "        \n",
    "    print (f\"Schritte: {steps}, Ergebnis: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d14aa1f-9867-4c16-b7e4-e8d672b7b2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ausführungsphase\n",
      "Schritte: 2748, Ergebnis: -26409\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae4908a-363c-46db-a771-9830240e4886",
   "metadata": {},
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd334f7e-95a0-4a10-8bd9-cb2bdf1fcb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(episodes):\n",
    "    print (\"Lernphase\")\n",
    "   \n",
    "    # Epsilon für Exploration\n",
    "    epsilon = 1\n",
    "    \n",
    "    # Lernparameter\n",
    "    alpha = 0.6\n",
    "    gamma = 1\n",
    "    scores = []\n",
    "    \n",
    "    # Lernen\n",
    "    for episode in range(episodes):\n",
    "        # Zurücksetzen der Umgebung vor jeder neuen Episode, Merken des Startzustandes\n",
    "        state = env.reset()\n",
    "        # Variablen initialisieren\n",
    "        score = 0\n",
    "        done = False\n",
    "        \n",
    "        # Gehe bis zum Spielende für jede Episode durch\n",
    "        while(done == False):\n",
    "            \n",
    "            # Wähle die am besten bewertete Aktion mit Wahrscheinlichkeit 1-epsilon\n",
    "            if random.uniform(0, 1) > epsilon:\n",
    "                action = np.argmax(Q1[state, :])\n",
    "            else:\n",
    "                # Sonst führe eine zufällige Aktion aus\n",
    "                action = env.action_space.sample()\n",
    "            \n",
    "            \n",
    "            # Führe die ausgewählte Aktion aus\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            \n",
    "            # Aktualisierung der Q Werte, Index ist aktueller Status und die ausgeführte Aktion\n",
    "            # Q-Learning Formel\n",
    "            Q1[state, action] = (1 - alpha) * Q1[state, action] + alpha * (reward + gamma * np.max(Q1[next_state, :]))\n",
    "            \n",
    "            # Neuen Zustand setzen\n",
    "            state = next_state\n",
    "            \n",
    "            \n",
    "        scores.append(score)\n",
    "        # Zeige die Bewertungen einer Episode graphisch über der Anzahl Episoden an\n",
    "        plot.plot(scores, \".\")\n",
    "        \n",
    "        # Ausgabe alle 1000 Episoden\n",
    "        if(episode % 10 == 0):\n",
    "            print (f\"Iteration: {episode}, Ergebnis: {score}\")\n",
    "                    \n",
    "        # Epsilon für jede Episode reduzieren falls es noch über einem Minimalwert liegt\n",
    "        if (epsilon > 0.01):\n",
    "            epsilon *= 0.98\n",
    "            \n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc49292-8a3c-4723-a469-e35f202bbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(cycles):\n",
    "    print (\"Ausführungsphase\")    \n",
    "    \n",
    "    all_steps = 0\n",
    "    scores = 0\n",
    "    \n",
    "    for cycle in range(cycles):\n",
    "        \n",
    "        # Zurücksetzen der Umgebung und Variablen initialisieren\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        steps = 0\n",
    "        \n",
    "        if (cycle == 99):\n",
    "            # Startzustand anzeigen (letzter Lauf)\n",
    "            env.render()\n",
    "    \n",
    "        while(done == False):\n",
    "            # Zähle Schritte bis zum Ziel hoch\n",
    "            steps += 1\n",
    "            # Wähle die am Besten bewertete Aktion aus\n",
    "            action = np.argmax(Q1[state, :])\n",
    "            # Führe die ausgewählte Aktion aus\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            # Weitergehen\n",
    "            state = next_state\n",
    "        \n",
    "            if (cycle == 99):\n",
    "                # Zeige den aktuellen Zustand für den letzten Lauf\n",
    "                env.render()\n",
    "                \n",
    "        all_steps += steps\n",
    "        scores += score\n",
    "                \n",
    "        if (cycle == 99):\n",
    "            print (f\"Schritte: {steps}, Ergebnis: {score}\")\n",
    "        \n",
    "    print ((f\"Für {cycles} Zyklen: durchschnittliche Schritte zum Ziel {all_steps/cycles}, durchschnittliches Ergebnis: {scores/cycles}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "044b64c5-e69e-46cf-b08c-6bc530eeecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lernphase\n",
      "Iteration: 0, Ergebnis: -31557\n",
      "Iteration: 10, Ergebnis: -2939\n",
      "Iteration: 20, Ergebnis: -263\n",
      "Iteration: 30, Ergebnis: -786\n",
      "Iteration: 40, Ergebnis: -146\n",
      "Iteration: 50, Ergebnis: -133\n",
      "Iteration: 60, Ergebnis: -226\n",
      "Iteration: 70, Ergebnis: -13\n",
      "Iteration: 80, Ergebnis: -124\n",
      "Iteration: 90, Ergebnis: -24\n",
      "Ausführungsphase\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  x  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  x  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  x  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  x  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  x  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  x  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  x  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  x  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  x  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  x  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  x\n",
      "\n",
      "Schritte: 13, Ergebnis: -13\n",
      "Für 100 Zyklen: durchschnittliche Schritte zum Ziel 13.0, durchschnittliches Ergebnis: -13.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrix für Q-Werte, initial auf 0\n",
    "Q1 = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "\n",
    "learn(100)\n",
    "execute(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b432e3e-4c70-4804-bb57-6c72b199c8ce",
   "metadata": {},
   "source": [
    "# SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79c85c5c-f7a0-4c91-8a1b-963446a89c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, epsilon):\n",
    "    # Wähle die am besten bewertete Aktion mit Wahrscheinlichkeit 1-epsilon\n",
    "    if random.uniform(0, 1) > epsilon:\n",
    "        action = np.argmax(Q2[state, :])\n",
    "    else:\n",
    "        # Sonst führe eine zufällige Aktion aus\n",
    "        action = env.action_space.sample()\n",
    "    return action        \n",
    "            \n",
    "    \n",
    "def learn(episodes):\n",
    "    print (\"Lernphase\")\n",
    "    \n",
    "    # Epsilon für Exploration\n",
    "    epsilon = 1\n",
    "    \n",
    "    # Lernparameter\n",
    "    alpha = 0.2\n",
    "    gamma = 1\n",
    "    scores = [];\n",
    "    \n",
    "    \n",
    "    # Lernen\n",
    "    for episode in range(episodes):\n",
    "        # Zurücksetzen der Umgebung vor jeder neuen Episode, Merken des Startzustandes\n",
    "        state = env.reset()\n",
    "        # Variablen initialisieren\n",
    "        score = 0\n",
    "        done = False\n",
    "        action = get_action(state, epsilon)\n",
    "        \n",
    "        while(done == False):\n",
    "                        \n",
    "            # Führe die ausgewählte Aktion aus\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            \n",
    "            # Nächste Aktion aus dem nächsten Zustand errechnen, diese kann auch zufällig sein\n",
    "            next_action = get_action(next_state, epsilon)\n",
    "            \n",
    "            # Aktualisierung der Q Werte, Index ist aktueller Status und die ausgeführte Aktion\n",
    "            # SARSA Formel\n",
    "            Q2[state, action] = (1 - alpha) * Q2[state, action] + alpha * (reward + gamma * Q2[next_state, next_action])\n",
    "            \n",
    "            # Neuen Zustand und nächste Aktion setzen\n",
    "            state = next_state\n",
    "            action = next_action\n",
    "            \n",
    "        scores.append(score)\n",
    "        # Zeige die Bewertungen einer Episode graphisch über der Anzahl Episoden an\n",
    "        plot.plot(scores, \".\")\n",
    "            \n",
    "        # Ausgabe alle 1000 Episoden\n",
    "        if(episode % 10 == 0):\n",
    "            print (f\"Iteration: {episode}, Ergebnis: {score}\")\n",
    "            \n",
    "        # Epsilon reduzieren falls es noch über einem Minimalwert liegt\n",
    "        if (epsilon > 0.01):\n",
    "            epsilon *= 0.98\n",
    "            \n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e21d3cf0-467c-4f53-b62e-20548d3de3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(cycles):\n",
    "    print (\"Ausführungsphase\")    \n",
    "    \n",
    "    all_steps = 0\n",
    "    scores = 0\n",
    "    \n",
    "    for cycle in range(cycles):\n",
    "        \n",
    "        # Zurücksetzen der Umgebung und Variablen initialisieren\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        steps = 0\n",
    "        \n",
    "        if (cycle == 99):\n",
    "            # Startzustand anzeigen (letzter Lauf)\n",
    "            env.render()\n",
    "    \n",
    "        while(done == False):\n",
    "            # Zähle Schritte bis zum Ziel hoch\n",
    "            steps += 1\n",
    "            # Wähle die am Besten bewertete Aktion aus\n",
    "            action = np.argmax(Q2[state, :])\n",
    "            # Führe die ausgewählte Aktion aus\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            # Weitergehen\n",
    "            state = next_state\n",
    "        \n",
    "            if (cycle == 99):\n",
    "                # Zeige den aktuellen Zustand für den letzten Lauf\n",
    "                env.render()\n",
    "                \n",
    "        all_steps += steps\n",
    "        scores += score\n",
    "                \n",
    "        if (cycle == 99):\n",
    "            print (f\"Schritte: {steps}, Ergebnis: {score}\")\n",
    "        \n",
    "    print ((f\"Für {cycles} Zyklen: durchschnittliche Schritte zum Ziel {all_steps/cycles}, durchschnittliches Ergebnis: {scores/cycles}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634b627d-0c26-4da4-9f83-b76523ad32a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lernphase\n",
      "Iteration: 0, Ergebnis: -85288\n",
      "Iteration: 10, Ergebnis: -603\n",
      "Iteration: 20, Ergebnis: -162\n",
      "Iteration: 30, Ergebnis: -135\n",
      "Iteration: 40, Ergebnis: -29\n",
      "Iteration: 50, Ergebnis: -23\n",
      "Iteration: 60, Ergebnis: -24\n",
      "Iteration: 70, Ergebnis: -21\n",
      "Iteration: 80, Ergebnis: -18\n",
      "Iteration: 90, Ergebnis: -26\n",
      "Ausführungsphase\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  x  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  x  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  x  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  x  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  x  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  x  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  x  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  x  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  x  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  x  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  x\n",
      "\n",
      "Schritte: 17, Ergebnis: -17\n",
      "Für 100 Zyklen: durchschnittliche Schritte zum Ziel 17.0, durchschnittliches Ergebnis: -17.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrix für Q-Werte, initial auf 0\n",
    "Q2 = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "\n",
    "learn(100)\n",
    "execute(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b5290-7552-47d8-bacc-36d82061e8c1",
   "metadata": {},
   "source": [
    "## Sarsamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad2af538-b060-448b-bed1-6870f77295bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, epsilon):\n",
    "    # Wähle die am besten bewertete Aktion mit Wahrscheinlichkeit 1-epsilon\n",
    "    if random.uniform(0, 1) > epsilon:\n",
    "        action = np.argmax(Q2[state, :])\n",
    "    else:\n",
    "        # Sonst führe eine zufällige Aktion aus\n",
    "        action = env.action_space.sample()\n",
    "    return action        \n",
    "            \n",
    "    \n",
    "def learn(episodes):\n",
    "    print (\"Lernphase\")\n",
    "    \n",
    "    # Epsilon für Exploration\n",
    "    epsilon = 1\n",
    "    \n",
    "    # Lernparameter\n",
    "    alpha = 0.2\n",
    "    gamma = 1\n",
    "    scores = [];\n",
    "    \n",
    "    \n",
    "    # Lernen\n",
    "    for episode in range(episodes):\n",
    "        # Zurücksetzen der Umgebung vor jeder neuen Episode, Merken des Startzustandes\n",
    "        state = env.reset()\n",
    "        # Variablen initialisieren\n",
    "        score = 0\n",
    "        done = False\n",
    "        action = get_action(state, epsilon)\n",
    "        \n",
    "        while(done == False):\n",
    "                        \n",
    "            # Führe die ausgewählte Aktion aus\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            \n",
    "            # Nächste Aktion aus dem nächsten Zustand errechnen, diese kann auch zufällig sein\n",
    "            next_action = get_action(next_state, epsilon)\n",
    "            \n",
    "            # Aktualisierung der Q Werte, Index ist aktueller Status und die ausgeführte Aktion\n",
    "            # Sarsamax Formel\n",
    "            Qsa_next = np.max(Q3[next_state, :]) if next_state is not None else 0  # value of next state \n",
    "            Q3[state, action] = (1 - alpha) * Q3[state, action] + alpha * (reward + gamma * Qsa_next)\n",
    "            \n",
    "            # Neuen Zustand und nächste Aktion setzen\n",
    "            state = next_state\n",
    "            action = next_action\n",
    "            \n",
    "        scores.append(score)\n",
    "        # Zeige die Bewertungen einer Episode graphisch über der Anzahl Episoden an\n",
    "        plot.plot(scores, \".\")\n",
    "            \n",
    "        # Ausgabe alle 1000 Episoden\n",
    "        if(episode % 10 == 0):\n",
    "            print (f\"Iteration: {episode}, Ergebnis: {score}\")\n",
    "            \n",
    "        # Epsilon reduzieren falls es noch über einem Minimalwert liegt\n",
    "        if (epsilon > 0.01):\n",
    "            epsilon *= 0.98\n",
    "            \n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ada5e1c2-6671-4267-854d-16c8f925ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(cycles):\n",
    "    print (\"Ausführungsphase\")    \n",
    "    \n",
    "    all_steps = 0\n",
    "    scores = 0\n",
    "    \n",
    "    for cycle in range(cycles):\n",
    "        \n",
    "        # Zurücksetzen der Umgebung und Variablen initialisieren\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        steps = 0\n",
    "        \n",
    "        if (cycle == 99):\n",
    "            # Startzustand anzeigen (letzter Lauf)\n",
    "            env.render()\n",
    "    \n",
    "        while(done == False):\n",
    "            # Zähle Schritte bis zum Ziel hoch\n",
    "            steps += 1\n",
    "            # Wähle die am Besten bewertete Aktion aus\n",
    "            action = np.argmax(Q3[state, :])\n",
    "            # Führe die ausgewählte Aktion aus\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            # Weitergehen\n",
    "            state = next_state\n",
    "        \n",
    "            if (cycle == 99):\n",
    "                # Zeige den aktuellen Zustand für den letzten Lauf\n",
    "                env.render()\n",
    "                \n",
    "        all_steps += steps\n",
    "        scores += score\n",
    "                \n",
    "        if (cycle == 99):\n",
    "            print (f\"Schritte: {steps}, Ergebnis: {score}\")\n",
    "        \n",
    "    print ((f\"Für {cycles} Zyklen: durchschnittliche Schritte zum Ziel {all_steps/cycles}, durchschnittliches Ergebnis: {scores/cycles}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "363311d8-48b0-4500-96aa-5e2c262365cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lernphase\n",
      "Iteration: 0, Ergebnis: -15603\n",
      "Iteration: 10, Ergebnis: -55\n",
      "Iteration: 20, Ergebnis: -311\n",
      "Iteration: 30, Ergebnis: -225\n",
      "Iteration: 40, Ergebnis: -128\n",
      "Iteration: 50, Ergebnis: -22\n",
      "Iteration: 60, Ergebnis: -148\n",
      "Iteration: 70, Ergebnis: -28\n",
      "Iteration: 80, Ergebnis: -21\n",
      "Iteration: 90, Ergebnis: -23\n",
      "Ausführungsphase\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28032/4023001811.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28032/925345110.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(cycles)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0msteps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m# Wähle die am Besten bewertete Aktion aus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[1;31m# Führe die ausgewählte Aktion aus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\reinforcement_learning\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\reinforcement_learning\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     \"\"\"\n\u001b[0;32m   1215\u001b[0m     \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'keepdims'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NoValue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\reinforcement_learning\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrix für Q-Werte, initial auf 0\n",
    "Q3 = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "\n",
    "learn(100)\n",
    "execute(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
